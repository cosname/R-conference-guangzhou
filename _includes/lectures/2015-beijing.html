<table>
  <tbody>
    <tr class="success">
      <th>嘉宾介绍</th>
      <th>演讲摘要</th>
    </tr>

<tr>
    <td><b>郁彬（UC Berkeley）</b><br><br>Bin Yu is Chancellor’s Professor in the Departments of Statistics and of Electrical Engineering & Computer Science at the University of California at Berkeley.  Her current research interests focus on statistics and machine learning theory, methodologies, and algorithms for solving high- dimensional data problems. Her group is engaged in interdisciplinary research with scientists from genomics, neuroscience, and remote sensing.

She obtained her B.S. degree in Mathematics from Peking University in 1984, her M.A.and Ph.D. degress in Statistics from the University of California at Berkeley in 1987 and 1990, respectively.

She held faculty positions at the Univ of Wisconsin-Madison and Yale University and was a Member of Technical Staff at Bell Labs, Lucent. She was Chair of Department of Statistics at UC Berkeley from 2009 to 2012, and is a founding co-director of the Microsoft Lab on Statistics and Information Technology at Peking University, China, and Chair of the Scientific Advisory Committee of the Statistical Science Center at Peking University.

She is Member of the U.S. National Academy of Sciences and Fellow of the American Academy of Arts and Sciences. She was a Guggenheim Fellow in 2006, an Invited Speaker at ICIAM in 2011, and the Tukey Memorial Lecturer of the Bernoulli Society in 2012. She was President of IMS (Institute of Mathematical Statistics) in 2013-2014, and will be the Rietz Lecturer of IMS in 2016.</td>
    <td><b>The multi-facets of a data science project to answer: how are organs formed?</b><br><br>Genome wide data reveal an intricate landscape where gene actions and interactions in diverse spatial areas are common both during development and in normal and abnormal tissues.

Understanding local gene networks is thus key to developing treatments for human diseases.

Given the size and complexity of recently available systematic spatial data, defining the biologically relevant spatial areas and modeling the corresponding local biological networks present an exciting and on-going challenge. It requires the integration of biology, statistics and computer science; that is, it requires data science.

In this talk, I present results from a current project co-led by biologist Erwin Frise from Lawrence Berkeley National Lab (LBNL) to answer the fundamental systems biology question in the talk title.

My group (Siqi Wu, Antony Joseph, Karl Kumbier) collaborates with Dr. Erwin and other biologists (Ann Hommands) of Celniker's Lab at LBNL that generate the Drosophila spatial expression embryonic image data.  We leverage our group's prior research experience from computational neuroscience to use appropriate ideas of statistical machine learning in order to create a novel image representation decomposing spatial data into building blocks (or principal patterns).

These principal patterns provide an innovative and biologically meaningful approach for the interpretation and analysis of large complex spatial data. They are the basis for constructing local gene networks, and we have been able to reproduced almost all the links in the Nobel-prize winning (local) gap-gene network. In fact, Celniker's lab is running knock-out experiments to validate our predictions on gene-gene interactions.

Moreover, to understand the decomposition algorithm of images, we have derived sufficient and almost necessary conditions for local identifiability of the algorithm in the noiseless and complete case.  

Finally, we are collaborating with Dr. Wei Xue from Tsinghua Univ to devise a scalable open software package to manage the acquisition and computation of imaged data, designed in a manner that will be usable by biologists and expandable by developers.</td>
</tr>


<tr>
    <td><b>张潼（百度大数据实验室）</b><br><br>张潼博士现在是百度大数据实验室的负责人，并且是美国新泽西大学统计系教授。他是机器学习，大数据分析和统计学领域的国际知名学者以及美国统计学会的Fellow。他在国际权威的机器学习期刊担任编辑，并且曾经参与过美国科学院大数据专家委员会。张潼本科毕业于美国康奈尔大学，并且在美国斯坦福大学获得了计算机科学的博士学位。</td>
    <td><b>互联网的大数据实践</b><br><br>作为国内最大的互联网公司之一，百度在大数据实践上积累了很多经验。在这个报告里我介绍一下百度大数据的一些案例，技术积累，和挑战。</td>
</tr>

<tr>
    <td><b>李舰（堡力山集团）</b><br><br>李舰，毕业于中国人民大学统计学院（本科）和北京大学软件与微电子学院（研究生），现就职于堡力山集团，担任副总。是Rweibo、Rwordseg、tmcn等R包的作者，《数据科学中的R语言》的作者，还参与翻译了《R语言核心技术手册》和《机器学习与R语言》。邮箱：lijian.pku@gmail.com，主页：http://jianl.org/</td>
    <td><b>R语言中的最优化方法</b><br><br>R是一个专业的统计计算环境，但同时也是一个非常灵活的开发平台。最优化方法本来不是R擅长的领域，但是这些年随着R语言越来越流行，很多作者将不少非常优秀的最优化工具整合到了R环境中，赋予了R更强大的功能。



本次报告将会结合演讲者的工作经验，介绍非线性规划、线性规划、非线性混合整数规划、遗传算法等业界常用的最优化方法及其在R环境中的实现方式，此外，还会针对这些最优化方法的应用场景与运行性能和商业软件进行比较。</td>
</tr>


<tr>
    <td><b>张俊妮（北京大学光华管理学院）</b><br><br>张俊妮为北京大学光华管理学院统计学副教授。1998年毕业于中国科学技术大学，获计算机软件学士学位；2002年毕业于美国哈佛大学，获统计学博士学位。研究领域为因果推断、贝叶斯分析、小区估计、数据挖掘以及文本挖掘。</td>
    <td><b>Distillation of News Flow into Analysis of Stock Reactions</b><br><br>News carry information of market moves.  The gargantuan plethora of opinions, facts and tweets on financial business offers the opportunity to test and analyze the influence of such text sources on future directions of stocks.  It also creates though the necessity to distill via statistical technology the informative elements of this prodigious and indeed colossal data source.  Using mixed text sources from professional platforms, blog fora and stock message boards we distill via different lexica sentiment variables. These are employed for an analysis of stock reactions: volatility, volume and returns.  An increased (negative) sentiment will influence volatility as well as volume.  This influence is contingent on the lexical projection and different across GICS sectors.  Based on review articles on 100 S&P 500 constituents for the period of October 20, 2009 to October 13, 2014 we project into BL, MPQA, LM lexica and use the distilled sentiment variables to forecast individual stock indicators in a panel context.  Exploiting different lexical projections, and using different stock reaction indicators we aim at answering the following research questions:

(i)	Are the lexica consistent in their analytic ability to produce stock reaction indicators, including volatility, detrended log trading volume and return?

(ii) To which degree is there an asymmetric response given the sentiment scales (positive v.s. negative)?

(iii) Are the news of high attention firms diffusing faster and result in more timely and efficient stock reaction? 

(iv) Is there a sector specific reaction from the distilled sentiment measures?

We find there is significant incremental information in the distilled news flow.  The three lexica though are not consistent in their analytic ability.  Based on confidence bands an asymmetric, attention-specific and sector-specific response of stock reactions is diagnosed.</td>
</tr>


<tr>
    <td><b>王菲菲（北京大学光华管理学院）</b><br><br>王菲菲，北京大学光华管理学院商务统计与经济计量系博士研究生，2012年毕业于中国人民大学统计学院，获经济学学士学位。感兴趣的研究领域有：文本挖掘，贝叶斯分析等。目前的研究课题集中在本挖掘领域，尤其是主题模型在营销领域中的应用、中文分词以及文档分类等。</td>
    <td><b>Semi-supervised Document Classification through a Bayesian Hierarchical Model of Latent Topics</b><br><br>文档分类是有效组织大规模文档的第一步。通过借鉴潜在狄利克雷模型（LDA）以及它的扩展模型的研究思路，本文提出了一种半监督文档分类模型，即基于潜在主题的贝叶斯层次模型。该模型假设每个大类都可细分为一些独特的主题，同时各大类共享一个公共主题；每个主题，包括从属于某个类别的主题以及公共主题，在词典空间上都各有一个概率分布。本文使用MCMC方法对模型进行估计，在建模时同时使用已分类文档和未分类文档，并预测出未分类文档的类别。该模型被用于几个实际数据集，并和使用标准LDA模型得到主题分布，然后使用随机森林和支持向量机建立分类器的两阶段方法进行了对比。结果显示，本文提出的贝叶斯层次模型能够显著提高分类正确率，且结果稳定。</td>
</tr>


<tr>
    <td><b>张江（北京师范大学系统科学学院）</b><br><br>张江，北京师范大学系统科学学院副教授，集智俱乐部创始人，主要研究领域包括：复杂系统建模与分析，涵盖互联网上的集体注意力流、城市复杂系统的建模分析等。</td>
    <td><b>Collective Attention Flows on the Web</b><br><br>In information age, human attention has been becoming a scarce resource. To know how collective attention flowing on the sea of information resources is of importance. We model collective attention flows as open flow networks. In the first study, we embed the network of the Indiana university clickstream data into a high dimension space and show how attention distributing on websites. Second, we show the flows of collective attention along various paths in the network may determine the success of an online community by the users' behavior data of the largest ask-answer community stackexchange. Third, we study 30,000 online forums of Baidu Tieba, and show that forums resembling organisms have metabolism and obey the generalized Kleiber law. The scaling exponent of the Kleiber law can be treated as a novel and stable indicator of stickness of the given forum.</td>
</tr>


<tr>
    <td><b>陈丽云（eBay）</b><br><br>我在eBay做数据分析，天天跟随机实验打交道，日子久了就顺便玩点好玩的分析。另有博客名“落园”，故有时候自诩落园园主，顺手写点好玩的故事。</td>
    <td><b>网站随机实验中的方差 (Variance Deduction in Online Randomized Experiments)</b><br><br>网站实验一般呈现“弱信号”特征：实验效果淹没在海量数据中（多重数据来源、复杂数据纬度），加之用户本身的异质性。很多时候随机实验成为了做一个公平的比较的最好的办法、以期从盘根错节的各种相关关系形成的网络中寻得一丝丝因果关系的脉络。在此之上，我们还希望可以进一步的减少噪音（方差）从而得到更清晰的信号，同时也好奇是不是不同特质的用户会对实验有着迥异的反应。在这个演讲中我将从实践的角度介绍一些提高估计效率（降低方差）和分析异质效应的模型。

Online experiments often shows the weak signal problem among massive data set and huge heterogeneity in user behaviors. Though a random experimental design helps disentangle casual effects from correlationships, we still want to reduce the noise (variance) and obtain better signals; in addition, we want to learn if the treatment affects different users differently. In this talk I will go through some variance deduction and heterogeneous treatment effect models from a practical point of view.</td>
</tr>


<tr>
    <td><b>刘思喆（京东商城）</b><br><br>刘思喆先生，于2012年加入京东商城， 历任京东商城数据部高级算法工程师、个性化推荐组经理、推荐搜索部高级经理，现主要负责关联推荐产品的策略改进以及算法优化。14年获得京东“数据达人”称号，京东技术学院金牌讲师。同时也是中国人民大学大数据分析实验班、中央财经大学统计系校外导师。工作之余，刘思喆专注于数据科学领域，尤其对R语言，是《153分钟学会R》的作者以及《R核心技术手册》的译者。</td>
    <td><b>京东商城推荐算法实践</b><br><br>京东的推荐系统从2013年开始向第二代过渡，本次分享将从京东的推荐系统产品定位出发，阐述系统的架构、算法和策略的实践，以及对未来的优化方向的思考。</td>
</tr>


<tr>
    <td><b>常象宇（西安交通大学管理学院，数据科学与信息质量研究中心）</b><br><br>常象宇，毕业于西安交通大学数学与应用数学系。现为西安交通大学管理学院数据科学与信息质量研究中心助理教授。主要研究统计机器学习，高维统计分析与商务智能等。</td>
    <td><b>分布式回归算法的参数设置</b><br><br>解决大规模数据的统计计算的基本想法之一是分布式计算。分而治之的思想是分布式计算的一种主流策略。该策略的基本思想是把某一大规模数据集分成（Split）可被计算的小块数据，然后把小块数据的计算结果集成（Combine）回来作为最终的计算结果。例如分布式计算的MapReduce的框架，R中的plyr包等都是基于上述策略开发的。使用分而治之的策略进行统计计算，必然在参数设置上遇到两个问题：第一，应该把数据分成多少块？第二，对于每块数据使用某种统计模型如何设置该模型参数？本演讲讲会针对回归问题从统计理论与实验上部分回答上述两个问题。从而解释例如分布式K紧邻回归，Nadaraya-Watson估计，线性回归和桥回归的参数如何设置。</td>
</tr>


<tr>
    <td><b>马莹莹（北京大学）</b><br><br>北京大学光华管理学院统计系博士生，2012-2013年曾在USC Marshall 商学院访问。研究兴趣集中在付费搜索广告、社交网络、高维数据分析。</td>
    <td><b>具有低维因子结构的高维两样本检验</b><br><br>本文针对具有低维因子结构的高维两样本数据提出了一种新型检验方法，这种检验方法适用的对象包括：股票收益率数据，搜索引擎营销数据，超市销售数据等具有典型低维因子特征的高维数据。本文提出了新的检验方法，并给出了此检验方法的渐进理论性质，最后，本文通过股票收益率数据分析来举例说明此种检验方法如何应用到实际的数据分析中。</td>
</tr>


<tr>
    <td><b>殷腾飞（Seven Bridges Genomics）</b><br><br>南开大学生命科学本科，ISU遗传学博士辅修统计，Genentech两次暑期实习与工作，现任波士顿Seven Bridges Genomics生物信息云计算公司可视化部门产品经理。BioVis 2015委员会成员。开发维护了10+ CRAN和Bioconductor的软件包。</td>
    <td><b>R在Seven Bridges Genomics平台上的开发，部署，使用和分享</b><br><br>Seven Bridges Genomics是全球领先的生物信息云计算公司，为全球多家企业和研究机构，以及美国国家政府和英国国家政府提供基因组分析的云计算存储和分析解决方案。生物信息是生物，计算机和数学统计碰撞产生的火花，SBG同样致力于对开源社区和开源语言的支持，基于docker和common workflow languange标准流程描述语言的rabix项目，可以轻量简单的在本地和SBG的云端进行开发部署与分享开源软件。本次报告，将介绍SBG平台对R语言的支持，包括云端文件的加载，Rstudio的使用，基于docker和rabix的R包的开发，部署和分享，以及如何与应用库里的已存工具进行对接，来完成生物数据的数据分析，挖掘和统计分析。</td>
</tr>


<tr>
    <td><b>徐文昕（西南大学）</b><br><br>西南大学数学与统计学院教师，经济计量方向。主要研究经济计量建模、应用， 极值与风险管理。</td>
    <td><b>某网站浏览者潜在需求研究</b><br><br>通过对某网站浏览者访问数据的分析，试图理解潜在客户的需求，为潜在客户画像，并对网站的业务构成提出一些建议。</td>
</tr>




<tr>
    <td><b>周静（北京大学光华管理学院）</b><br><br>北京大学光华管理学院市场营销系博士研究生，2012年于中央财经大学获管理学学士学位。博士期间的研究方向为营销模型，主要的工作重点是通过网络数据建模解决实际营销问题，如基于移动社交网络的消费者促销模型、网络抽样技术、社交媒体上的消费者行为，重点关注基于朋友间互相依存关系的选择行为。</td>
    <td><b>个体网络特征对客户流失的影响</b><br><br>客户流失是客户关系管理中一个比较经典的研究议题，之前的研究重点关注影响客户流失的内在因素，如研究人员探索了很多能显著影响客户流失的因素。最近由于社交网络的兴起，一些研究者开始将目光投向社交网络信息，用户的社交信息是否和他的离网有显著关系呢？我们用某移动运营商的数据进行客户的个体网络特征与其离网行为的研究，这里我们主要考虑三个因素：分别是通话人数、人均通话时长和人均通话时长的分布，初步的分析结果显示通话人数和流失率存在显著的负相关关系，利用该流失预警模型，我们对该移动运营商进行了未来流失人群的预测，根据实际结果，我们模型的预测精度可以达到70%，这大大降低了该公司在挽留高风险客户上的成本。</td>
</tr>


<tr>
    <td><b>王汉生（北京大学光华管理学院）</b><br><br>王汉生1998年北京大学数学学院概率统计系本科毕业，2001年美国威斯康星大学麦迪逊分校统计系博士毕业。现任北京大学光华管理学院商务统计与经济计量系教授，博士生导师，系主任；北京大学商务智能研究中心主任；博雅立方科技有限公司首席科学家；微信公众号“狗熊会”创始人。近年来，他发表英文学术论文共计五十余篇，中文论文近二十篇。合著英文专著1本，独立完成中文教材2本，先后担任多个学术刊物副主编(Associate Editor)。此次入选美国统计协会（American Statistical Association）2014年会士（Fellow）。</td>
    <td><b>网络结构数据与互联网征信</b><br><br>面向小微商户以及个人消费的小微信贷是当前互联网金融的重要发展方向，并且正在经历爆发式增长。在这个增长过程中，如何在没有实物抵押的情况下，通过互联网大数据分析，实现快速准确征信是一个非常重要的问题。为此，不同的数据都可以做出一定的贡献。例如：消费、缴费、职业、人口统计特征等。但是，我们认为在着所有数据中，基于社交网络的网络结构数据是最为重要的，扮演者核心的角色。网络结构数据给信贷方提供了两个重要的支持。第一、通过连接不同个体，提供了通过一个人的好友，增进对该个体了解的能力，能够极大地丰富并且补充数据。第二、在缺乏实物抵押的情况下，网络结构数据是一种重要的信用资产，是催收的重要手段。而本报告将从这两方面，通过实际案例，做出一定的分析和探讨。</td>
</tr>


<tr>
    <td><b>解环宇（北大光华）</b><br><br>北京大学光华管理学院11级解环宇 

6月份入职Citadel</td>
    <td><b>从一级市场的投行经历到二级市场的量化交易</b><br><br>1. 投行以及风投的一些经历，包括面试技巧及一些经验。2. 量化交易的一些经历，包括A股的一些交易策略以及潜在的交易机会</td>
</tr>


<tr>
    <td><b>吴睿（西安欧亚学院）</b><br><br>2006年就读于西安建筑科技大学应用数学专业硕士研究生，2009年加入西安欧亚学院</td>
    <td><b>某留学网站潜在客户浏览行为探究</b><br><br>通过对某留学网站潜在客户浏览数据的分析，试图理解潜在客户的需求，并尝试对网站结构以及业务构成提出一些建议。</td>
</tr>


<tr>
    <td><b>冯永昌（微量网）</b><br><br>冯永昌，央行互联网金融博士后，北大光华统计学博士，人大统计学学士，美国芝加哥大学访问学者。目前担任微量网创始人兼CEO，量邦集团董事长，北京大学对冲基金实验执行主任。</td>
    <td><b>用R语言进行高级量化投资——一个期货和期权组合的策略案例</b><br><br>报告提出用股指期货的日内程序化交易策略和做空波动率的期权组合形成风险对冲策略，即Risk-Neutral策略，模拟业绩显示复合策略大幅提升夏普比率，平滑曲线走势。这是用股指期权管控量化交易风险的一个实验性案例。报告也给出如何用R实现该案例的研究和交易。</td>
</tr>


<tr>
    <td><b>张常有（中国科学院软件研究所）</b><br><br>张常有，工学博士，中国科学院软件研究所副研究员。长期从事高性能计算、协同计算、智能信息网络方面的研究。中国计算机学会会员（高性能计算专业委会委员、协同计算专业委员会委员、青年科学家论坛YOCSEF委员）、中国人工智能学会会员（智能信息网络专业委员会委员）、国际杂志《IEEE Transaction on Signal Processing》和《International Journal of Automation and Computing》论文匿名审稿人。</td>
    <td><b>Julia语言进展及面向领域的支撑环境</b><br><br>Julia语言的语法对计算领域非常亲和，有很强的分布式高性能支持能力和数学库扩展能力。本报告第一部分介绍Julia语言的语法新特性，分享基本程序结构特征。第二部分重点阐述Julia语言对并行计算的支持能力和面向领域的工具库制作使用方法。第三部分介绍OpenBlas算法库方面的工作新进展。最后，阐述面向企业计算的高性能Julia云编程环境，示例基于深度学习的领域应用构建方法的近期尝试。</td>
</tr>


<tr>
    <td><b>陈钢（WeGene）</b><br><br>陈钢，2012年在中南大学获得计算机博士学位，之后加入深圳华大基因，历任研究员、副总监、副总裁等职。2015年4月加入WeGene，致力于构建面向中国人的个人基因组解读平台。</td>
    <td><b>机器学习在中国人祖源成分分析中的应用</b><br><br>以23andme、Ancestry.com为代表的美国个人基因组服务提供商利用近百万份人类基因组数据，构建起了面向全球用户的祖源成分分析系统。但在这些系统中，原本成分复杂的中国人都被抽象成了统一的Chinese。



我们试图通过收集中国人的祖源信息和基因组数据，整合公共数据库，利用支持向量机、隐马尔科夫等模型构建起面向中国人的祖源成分、姓氏起源和民族成分分析系统。



我们将自行收集的基因组和祖源信息跟HGDP项目的数据整合在一起，采用基因组上45万个跟祖源有密切关系的位点的基因型信息构建训练数据集。所有的位点根据其在基因组上的位置排序，划分滑动窗口。对每个窗口训练多分类支持向量机，并用隐马模型修整结果。所构建的系统已经在为用户提供祖源分析服务，并且随着训练数据的增加定期重建模型，优化分析结果。



该系统主要由Go语言编写，机器学习部分采用R语言，数据库采用了MongoDB和MySQL。</td>
</tr>


<tr>
    <td><b>马恩驰（京东商城）</b><br><br>京东商城推荐搜索部数据架构负责人，在个性化领域有丰富的经验，对推荐系统和RTB竞价广告有深入的研究。曾任随视传媒数据中心高级经理，主要负责RTB竞价算法的开发与优化、广告数据产品设计。现就职于京东商城，主要负责推荐和搜索业务数据架构的搭建与优化，推荐搜索报表平台、分析监控系统的设计与开发等工作。</td>
    <td><b>基于开源框架的推荐搜索BI系统</b><br><br>电商的推荐和搜索业务对BI系统有着极高的要求，海量点击流日志、复杂的实验分析、产品的快速迭代、多样化的分析需求使得BI系统面临更加严峻的挑战。我们主要从业务需求、架构设计、实验分析、产品优化等角度阐述京东推荐搜索在BI系统上的设计理念和实践经验。

作为数据挖掘人员比较喜爱的两门语言：R和python,我们在京东推荐搜索BI系统中大量的应用这两门语言，从TB级别的数据预处理、中间层的逻辑计算、不同实验间的数据分析、可视化图表展示。让每个数据从业人员真实的感受到R和python带给我们的价值。</td>
</tr>


<tr>
    <td><b>高涛（中国人民大学统计学院）</b><br><br>中国人民大学统计学院研究生三年级，统计之都编辑部成员，曾翻译《R语言实战》和《ggplot2: 数据分析与图形艺术》。研究兴趣：高维统计分析、概率图模型、大规模分布式算法</td>
    <td><b>高斯图模型应用和其大规模算法</b><br><br>本演讲将从经典高斯图模型出发，回顾高斯图模型各方向的进展以及相关应用，同时介绍大规模（高维情况）高斯图模型的学习算法。</td>
</tr>


<tr>
    <td><b>张云松（融360）</b><br><br>专注于量化模型，决策分析，互联网金融产品，曾就职于Experian,德勤等咨询公司，现为融360风控决策总监。</td>
    <td><b>互联网金融中的数据掘金者</b><br><br>互联网金融产业的火爆成了数据分析师的春天，四处高薪挖角来的分析师真的能给企业带来相应的回报么？如何能成为。演讲者将分享互联网金融中围绕数据相关的商业模式，分享企业级的数据模型平台构建，风控模型输出，征信数据服务，数据价值挖掘及数据产品化的经验。</td>
</tr>


<tr>
    <td><b>薄满辉（中航信移动科技有限公司）</b><br><br>航旅纵横创始人，中航信移动科技有限公司执行董事、总经理。毕业于复旦大学，北大光华MBA。2003年加入中国航信至今，在旅游交通信息化领域具有丰富的产品开发及项目管理经验。</td>
    <td><b>用数据智慧我们的出行</b><br><br>阐述航旅纵横的产品逻辑，用案例分析民航大数据在航旅纵横出行场景中的应用。</td>
</tr>


<tr>
    <td><b>颜林林（北京大学生命科学学院生物信息中心）</b><br><br>本人生物信息专业，爱好编程，崇尚开源。因统计只学到皮毛，故平时捣鼓R语言本身多于用R做统计。希望通过R会议的平台与其他同好互相交流学习。</td>
    <td><b>解构R语言中的“黑魔法”</b><br><br>R语言中有许多设计精妙的用法（比如管道），它们基于R语言本身灵活的语法支持，实现出了各种近乎神奇的效果。本次演讲将尝试用“重复发明轮子”的方法，尽可能简洁地来重建这些“暗黑魔法”，使大家能够理解它们背后的实现机制。演讲的具体内容预计包括：(1) 函数与自定义运算符 (2) 闭包与环境 (3) 延迟计算 (4) 语法解析和构建。</td>
</tr>


<tr>
    <td><b>刘路（中南大学数学与统计学院）</b><br><br>研究方向：随机过程的统计</td>
    <td><b>带图结构的大偏差理论</b><br><br>带有图结构的大偏差理论。图结构上经验分布的产生（模拟）。潜在的应用包含，判断网络结构（大规模）与某个体属性间的关联，估计个体属性在给定网络上的演化规律，通过局部信息估计网络的某些整体属性（如联通性，有无闭环）。</td>
</tr>


<tr>
    <td><b>李栋（中国城市规划设计研究院）</b><br><br>规划师，近期的研究兴趣是利用基于地理位置的新型数据开展城市和区域研究。</td>
    <td><b>位置数据分析对区域规划的启示</b><br><br>当前互联网、智能手机、各类地图和O2O应用的盛行催生了海量的位置数据，极大地扩展了传统地理信息数据的分析框架，这些用户生成的数据不仅仅对互联网行业意义重大，对城镇化、人口移动、群体行为模式等社会经济发展的重大问题同样具有参考价值。我们正在经历一场从传统数据向多源混合数据过渡的阶段，如何通过适当的分析手段，基于新型数据的视角来回答传统的社会问题，是当前主要的技术挑战。本次演讲基于位置微博、春运迁徙等公开数据为例，分享一些相关的尝试案例与实施感想。</td>
</tr>


<tr>
    <td><b>陈光（北京邮电大学）</b><br><br>陈光，1996级北邮电子系学生，现任北京邮电大学信息与通信工程学院副教授，研究方向为机器学习和文本计算，在数据分析和数据可视化方面有着广泛的兴趣。近年来，其指导的小组多次参加国际信息检索领域最权威的TREC评测，在包括微博检索、实体关系抽取等多个项目上多项指标取得第一。其新浪微博账号“爱可可-爱生活”，以领域的广阔视野，对业界的敏锐观察，丰富优质的资源推荐，为广大机器学习和数据科学爱好者所熟悉和喜爱。</td>
    <td><b>大数据时代的"读"者之道——社会化阅读趋势与应用</b><br><br>随着互联网的发展，由用户主导产生内容的互联网产品快速兴起，从信息匮乏到信息过载好像只在一瞬间，未来内容依旧为王，但重心已经由生产转向消费。大数据当前，多（有覆盖）、快（及时有效）、好（准确个性化）、省（时间&精力）已然成为用户的主要阅读需求，倡导分享、互动、传播的社会化阅读，能否助读者一臂之力，在信息汪洋里“得道”？作为用户，又该如何有效利用社交平台和社会化阅读平台高效获取有用信息？让我们一起深入探讨。</td>
</tr>


<tr>
    <td><b>谭乃强（北京品友互动）</b><br><br>谭乃强，毕业于湖南大学，现任品友互动资深算法工程师。</td>
    <td><b>Learning to Rank在RTB中的应用</b><br><br>Learning to Rank在RTB（实时交易平台）有大量的应用。对于DSP（需求方平台），需要需要衡量每一个用户的价值，并以合适的价格去竞到，由于竞争的存在，同样的准确率下，Ranking不一样，会导致竞价结果完全不一样。模型需要关注更多转化率（点击率）更高的用户。我们会讨论Learning to Rank在点击率，转化率和推荐系统的应用并分析各种评估Metric对效果的影响。</td>
</tr>


<tr>
    <td><b>宫雨（中国石油大学（北京））</b><br><br>中国石油大学(北京)商学院副教授，从事管理信息系统、数据挖掘方面的教学和研究工作。业余时间喜欢编写与统计计算软件相关的代码，对R及julia比较感兴趣，尤其是R和julia的分布式计算。</td>
    <td><b>rjulia：提高R计算效率的另外一条途径</b><br><br>rjulia结合了R和Julia两者的优点，提供了另外一条提高R计算效率的途径，为想要结合R和Julia的数据分析者提供了一个便利的工具。用户可以在计算密集的部分使用julia，而无需使用C/Fortran或Rcpp等语言来编写扩展包，降低了代码编写、调试的难度，同时也获得了效率提升。另外，还可利用julia的并行计算来进行大数据处理和分布式计算，对目前R尚不完善的分布式计算提供了补充。</td>
</tr>


<tr>
    <td><b>许小可（大连民族大学）</b><br><br>许小可，教授，硕士生导师。 2008年6月博士毕业于大连海事大学通信与信息系统专业，香港理工大学博士后,目前为大连民族大学学术带头人、民族信息资源挖掘与利用研究所所长,主要从事在线社交网络和非线性时间序列方面的研究工作。2013年入选辽宁省优秀人才支持计划，获得第一届CCF-腾讯犀牛鸟科研基金资助，在阿里巴巴数据创新大赛暨阿里巴巴青年学者支持计划一等奖；2014年获得大连市“青年科技之星”称号。</td>
    <td><b>社交网络中的亲属关系识别及应用</b><br><br>亲属关系一种非常特殊的强链接，在信息、舆情、谣言和行为传播中起到特殊的重要作用，我们与腾讯社交网络事业群合作对在线社交网络中的亲属关系进行了分析和识别。我们使用R语言程序包基于腾讯的QQ社交网络数据，首先比较了待检测用户的嵌入性、中心性以及离散度等指标来识别用户亲属关系的准确性高低，提出用户的亲属关系是一种局域强关系而非全局强关系的识别思想。根据该识别思路，通过度量节点被删除后对网络连通的破坏程度来定义该节点的局域重要性。对网络连通的破坏程度越大, 则说明被删除的节点越重要, 就越有可能是用户的亲属节点。由于本研究不但度量了用户之间的强弱关系，更重要的是基于网络结构特征识别出了用户和好友之间的关系类型，因此对于信息和行为传播规律的理论研究具有借鉴意义，对于病毒营销和计算广告学等实际应用具有指导作用。同时，基于在线社交网络的一对夫妻用户数据，通过视频可视化的方式演绎了他们各自建立社交圈子的过程以及两者之间社交关系的演化，从中可以看到他们相遇相识到相伴相守的全过程。</td>
</tr>


<tr>
    <td><b>李宜熹（台湾高雄第一科技大学金融系）</b><br><br>学历：台湾中山大学财务管理博士、中南大学管理科学与工程博士生

专长：金融风险管理

程式爱好：Matlab、EViews、R、Stata、Lingo</td>
    <td><b>ESG 经济情境产生器之系统开发</b><br><br>本演讲主要展演以 Orthogonal-ARMA-GARCH 方法论，以及采 Matlab 为工具所开发的经济情境产生器 (Economic Scenario Generator, ESG)。演讲的重点在于说明 ESG 的发展历程与用途、Orthogonal-ARMA-GARCH 方法论 以及对应 R 之套件的发展。</td>
</tr>


<tr>
    <td><b>任乾（厦门大学王亚南经济研究院）</b><br><br>厦门大学王亚南经济研究院硕士生，R语言用户，主要从事量化交易。</td>
    <td><b>C++/R工作环境配置</b><br><br>在一些有高性能计算的场景中，R通过Rcpp无缝调用C++在程序流、架构等诸多方面仍然不能满足需要。特别是系统框架本身在C++上实现，而在一些特定计算步骤中需要无缝内嵌R来完成时，RInside提供了完美的解决方案。本演讲即介绍Windows系统中基于mingw-w64工具链配置C++/R无缝内嵌工作环境的方法，并在此基础上通过量化策略回测的例子简要介绍SQLite/MySQL C/C++接口、boost::interprocess等工具。</td>
</tr>


<tr>
    <td><b>任坤（厦门大学王亚南经济研究院）</b><br><br>毕业于厦门大学金融系、王亚南经济研究院，R语言资深用户，learnR教程、pipeR、rlist扩展包的作者，在个人博客（http://renkun.me）中写了数十篇文章讨论数据分析相关工具、R语言高级编程等主题。主要兴趣为金融量化交易研究与工具开发。</td>
    <td><b>金融衍生品新时代中的量化分析工具链</b><br><br>以上证50ETF为标的的期权于2015年2月9日在上海证券交易所上市，开辟了国内金融衍生品市场新的篇章。随着各类限制逐渐放宽、各种衍生品工具的推出，对冲基金、量化交易则迎来了金融市场快速发展的新时代。掌握相关理论、熟练运用量化分析工具则成为了从事金融量化分析、研究领域的核心竞争力。该演讲以上证50ETF期权为例，简要分析其衍生品合约特征，基于市场高频行情数据，用R语言中的相关工具评估该市场的流动性，分析市场中存在的套利机会，并用可视化工具呈现了分析结果，并将该工作流程整合为自动化的日度报告。</td>
</tr>


<tr>
    <td><b>冯凌秉（江西财经大学 金融管理国际研究院）</b><br><br>男， 1988年5月生， 安徽合肥人。本科毕业于中南财经政法大学统计学专业，研究生毕业于中国人民大学统计学专业，博士毕业于澳大利亚国立大学。研究兴趣为应用统计与金融计量。</td>
    <td><b>imputeR: A General Imputation Framework</b><br><br>imputeR实现了缺失值插补的一个综合框架。此框架主要有两个特点：首先，其核心是在缺失值插补算法中利用了变量选择技术，以达到更好的插补精度并且保证了插补的收敛速度；此外，可用于该框架下的数据类型包括连续型数据，分类型数据和混合型数据，也即包含了在现实数据处理中所遇到的大多数数据类型。

本演讲将简述该框架的算法原理，并详细介绍imputeR包中实现该算法的具体函数。</td>
</tr>


<tr>
    <td><b>朱雪宁（北京大学）</b><br><br>北京大学光华管理学院商务统计系13级在读博士生。</td>
    <td><b>社交网络向量自回归模型</b><br><br>社交网络中充盈着各式各样的动态时间序列数据，为了刻画该类数据特征，我们建立了社交网络向量自回归模型（Network Vector Autoregression），并在建模过程利用了其特殊的社交网络结构信息。本演讲主要介绍模型的估计方法，二阶平稳条件，实际应用场景，以及基于微博数据的分析建模。</td>
</tr>


<tr>
    <td><b>黄浩军(Jason Copper)（腾讯科技（北京）有限公司）</b><br><br>毕业于北京大学 研究方向为自然语言处理与机器学习，现供职于腾讯科技（北京）-广点通-用户定向组。</td>
    <td><b>Natural Language Processing in a Deep Way</b><br><br>自然语言处理是以语言结构为研究对象的学科，与机器学习、人工智能、计算逻辑密切相关。受益于机器（深度）学习的发展，自然语言处理也取得了很大的进展。本文主要从深度学习角度介绍自然语言处理中词法、句法、语义等层面的最新进展，并对比传统模型分析深度学习的优点。从词法层面来看，自从Bengio在NIPS(2003)上提出神经网络语言模型以来，已经出现了各种类型的word embedding表示；句法层面，也出现了不少令人欣喜的工作（比如，Richard Socher的Recursive NN，Recursive Tensor NN等）；语义层面，结合形式模型，也存在不少不错的工作；更进一步的，在知识库辅助构建、扩充和推理等方面也有不俗的表现。</td>
</tr>


<tr>
    <td><b>周星（腾讯）</b><br><br>周星，2010年加入腾讯，先后从事搜索广告、长尾广告和社交广告的算法研发工作，负责开发了腾讯最早的大规模并行逻辑回归训练平台，组建了搜索广告和长尾广告的点击率预估团队，目前负责广点通转化优化方面的研发工作。专注于大规模机器学习技术、大数据处理技术和广告闭环生态建设。加入腾讯前，从事百度精准广告和搜索广告的算法研发工作。</td>
    <td><b>效果广告闭环生态建设——转化预估技术</b><br><br>著名广告大师约翰•沃纳梅克提出："我知道我的广告费有一半浪费了,但遗憾的是,我不知道是哪一半被浪费了"。作为互联网广告平台的一支新军，广点通以腾讯的生态系统为依托，基于大规模机器学习技术和大数据处理技术，解决了效果广告中的核心问题之一——转化预估。因此，面对约翰•沃纳梅克提出的难题，我们可以自豪的说：“在广点通，广告费中的每一分钱，都会有转化效果的保证。你在找的，正在找你！”



1. 效果广告闭环生态系统；

2. 转化跟踪技术；

3. 转化预估技术；

4. 大规模并行训练及特征工程技术；</td>
</tr>


<tr>
    <td><b>沈毅（百度）</b><br><br>ECharts 团队成员。ECharts-X 作者。目前专注于前端图形和可视化方向。</td>
    <td><b>图说 ECharts</b><br><br>ECharts 的简单介绍和演示。

ECharts 的目前状态，github 关注数等。

ECharts-X 分支介绍。globe viz 和 3D plots 的演示。

在 ECharts 3.0 中已经加入和即将加入的新特性。</td>
</tr>


<tr>
    <td><b>袁进辉（微软亚洲研究院）</b><br><br>袁进辉，现为微软亚洲研究院人工智能组研究员。2003年7于西安电子科技大学计算机学院获工学学士学位，同年免试推荐入清华大学计算机科学与技术系攻读博士学位（导师为张钹院士），研究方向为计算机视觉及机器学习应用，2008年7月于清华大学计算机科学与技术系获工学博士学位，同年留校做师资博士后，参与计算神经学科建设，并与李兆平等国际知名学者开展计算神经科学领域的相关研究。2011年加入网易有道任高级应用研究员，参与机器学习在多媒体、计算广告等领域的应用研究。2012年初加入北京万博科斯信息技术有限公司，任研发工程师，参与360搜索引擎研发工作。主要研究兴趣为计算机视觉、机器学习与视觉相关的神经科学。2004年至2007年，作为主要设计人员开发基于机器学习的视频镜头边界检测系统在美国标准技术研究院（NIST）组织的TRECVID评测中名列前茅，2008年，博士论文获清华大学优秀博士学位论文二等奖。2010年，负责中国斯诺克“鹰眼”系统核心模块研发，该系统已广泛应用于国际大赛和国家队日常训练。2012年，参与研发的360搜索引擎跃居国内市场份额第二。2013年8月起在微软亚洲研究院任职，研究兴趣包括大规模机器学习，神经网络的理论性质等。2014年发明LightLDA技术，把单个词Gibbs采样计算复杂度降到均摊O(1)，并把该算法并行化，可以用比已有工作显著少的计算资源完成显著更大规模的任务。业余时间喜欢在微博上发表段子。</td>
    <td><b>LightLDA: Making Super Large Topic Model Possible</b><br><br>When building large-scale machine learning (ML) programs, such as massive topic models or deep neural networks with up to trillions of parameters and training examples, one usually assumes that such massive tasks can only be attempted with industrial-sized clusters with thousands of nodes, which are out of reach for most practitioners and academic researchers. We consider this challenge in the context of topic modeling on web-scale corpora, and show that with a modest cluster of as few as 8 machines, we can train a topic model with 1 million topics and a 1-million-word vocabulary (for a total of 1 trillion parameters), on a document collection with 200 billion tokens --- a scale not yet reported even with thousands of machines. Our major contributions include: 1) a new, highly-efficient $\mathcal{O}(1)$ Metropolis-Hastings sampling algorithm, whose running cost is (surprisingly) agnostic of model size, and empirically converges nearly an order of magnitude more quickly than current state-of-the-art Gibbs samplers; 2) a model-scheduling scheme to handle the big model challenge, where each worker machine schedules the fetch/use of sub-models as needed, resulting in a frugal use of limited memory capacity and network bandwidth; 3) a differential data-structure for model storage, which uses separate data structures for high- and low-frequency words to allow extremely large models to fit in memory, while maintaining high inference speed. These contributions are built on top of the Petuum open-source distributed ML framework, and we provide experimental evidence showing how this development puts massive data and models within reach on a small cluster, while still enjoying proportional time cost reductions with increasing cluster size.</td>
</tr>


<tr>
    <td><b>王江浩（中国科学院地理科学与资源研究所）</b><br><br>从事GIS与遥感研究，侧重地理时空数据分析与挖掘，偏爱琢磨开源软件中的时空数据分析方法与可视化。</td>
    <td><b>R中的地理时空数据分析与可视化</b><br><br>地理空间信息和多维时间序列数据是大数据时代时常要面临的数据形式。如何从时空数据中科学地挖掘知识，形象地可视化这些高维复杂的数据是数据科学家们面临的新挑战。演讲者将针对实际问题，基于R开展时空数据分析方法研究，并分享如何利用时空统计和计算机技术来处理、分析、并交互可视化时空数据。</td>
</tr>


<tr>
    <td><b>王健（北京大学光华管理学院）</b><br><br>王健：北京大学光华管理学院商务统计与计量经济系博士研究生。毕业于吉林大学数学学院，本科专业为信息与计算科学。研究方向为文本挖掘，包括中文分词，文本分类，以及文本挖掘方法在企业社会责任研究中的应用。</td>
    <td><b>Integrating word segmentation with text classification</b><br><br>文档分类在文本挖掘领域有着广泛的应用。对中文数据而言，文本分类往往和分词联系在一起。比较常用的方法是先对中文文本进行分词，然后利用分词的结果建立模型实现文本分类，比如使用主题模型。本文将介绍一种结合分词和文本分类的新方法，通过分词从已分类文本中选出具有代表性的词，然后利用这些词帮助文本分类。即首先对已分类的训练数据进行分词，从中选取能够代表每个类别的“判别词”。在对测试数据进行建模时，结合分词和文档在各个类别上的概率分布信息，并对“判别词”的概率分布进行一定限制。模型的结果包括对测试数据中每篇文档的分词结果，以及每篇文档在所有类别上的概率分布，利用该概率分布即可对文档所属的类别进行预测。</td>
</tr>


<tr>
    <td><b>尤晓斌（National Healthcare Group, Singapore）</b><br><br>现任新加坡国立医疗集团数据分析员，曾就读于新加坡国立大学统计系和厦门大学统计系。有6年的R使用经历。兴趣领域为：贝叶斯统计，计算机统计学，统计学习，数据科学，可视化以及人口医疗相关分析。</td>
    <td><b>用数据科学优化人口健康模式</b><br><br>新加坡医疗系统在2014年Bloomberg医疗体系效率排名中位列第一。哈佛大学医学院教授哈兹尔廷用“价廉质优”一词，形容新加坡用4%的国内生产总值交出了一流成绩单——全民医疗覆盖，低婴儿死亡率和高预期寿命。

新加坡医疗系统同样面临人口老龄化的挑战。据估计，至2030年新加坡65岁以上的人口将超总过人口的20%。为了优化医疗系统以迎接人口老龄化的挑战，新加坡积极探索区域医疗模式，纵向整合综合医院，联合诊所，社区医院及疗养院等医疗资源，形成六大区域医疗协同合作的局面。

数据科学在探索区域医疗的过程中注入了新的科技活力。数据仓库的管理整合医疗机构运营数据以及SNOMED，ICD和WHO drug dictionary等标准化编码系统；统计学习建模能综合多方面信息协助决策；可视化及GIS有助于分析成果的阐释和理解。从数据预处理，建模到最终成果展示这一流程中，R语言都扮演着重要的角色。</td>
</tr>


<tr>
    <td><b>黄鑫（极光推送）</b><br><br>极光推送首席科学家，多年推荐系统，数据挖掘与产品开发架构经验，专注于大数据的落地和产品化应用。曾就职于豆瓣，珍爱网等互联网公司，曾参与多个产品的推荐算法设计，对社区的产品和运营都用着浓厚的兴趣，目前专注于大数据时代云服务的企业化发展和应用。</td>
    <td><b>情景化推荐算法的设计</b><br><br>在传统的推荐算法中，我们推荐算法设计的特征更多地依赖于条目的内容，以及用户与条目的评分等等静态特征，但是在移动互联网及智能硬件时代，我们却可以更多地捕获用户信息及其用户场景信息，在这次演讲中，会主要介绍基于用户情景以及用户当前实时状态的推荐算法设计，以及工程化中的实践经验。</td>
</tr>


<tr>
    <td><b>Zoom.Quiet（cmcm.com）</b><br><br>Python中文社区创始人(之一) / 管理员, 热心于 Python 等等社区的公益事业, 大家熟知的社区"大妈";



O.B.P (Open Book Proj.~中文蟒样开放图书计划) 及 蟒营(PythoniCamp) 工程设计者 /主持人; 参与并主持各种线上 / 线下活动; 主持编撰了 <<可爱的Python>> 坚持用 Pythonic 感化国人进入 FLOSS世界进行学习 / 分享 / 创造...</td>
    <td><b>R or Py 这是个问题</b><br><br>以数据科学为对象,探讨:

- 需要什么层次的能力

- 这些能力在 py 中怎么体现

- 是否需要学习 r 才能理解数据科学

- etc.

水平设定在初级的科普的.</td>
</tr>


<tr>
    <td><b>黄晶（百度）</b><br><br>黄晶，2009年硕士毕业于北京大学数学科学学院，加入百度工作。现任百度复合搜索部资深研发工程师，负责百度知心广告产品线的流量召回和点击率预估的研发工作</td>
    <td><b>transfer learning在广告点击率预估的应用</b><br><br>百度的知心广告有很多种展示形式，在做点击率预估的时候，我们会出现有些展现形式数据量不够的情况，我们采用transfer learning中的parameter base方法从其他展现形式“借”数据，很好的解决了部分展现形式数据量不够的问题。</td>
</tr>


<tr>
    <td><b>毕然（百度）</b><br><br>百度高级研究员。他在商业营销、在线广告、电信、国家安全等领域有丰富的大数据分析和建模经验。曾因对百度的杰出贡献，获得首届百度百万美金最高奖，并多次获得商业体系创新奖。专注于理论与实践的相互促进，在大数据分析与挖掘、经济与商业机制、营销与心理学、互联网产品战略几个方面都有涉猎，并深入研究其背后根源，融合并设计成课程。乐于分享，百度学院明星讲师，著有多个大数据分析与经济学原理的相关课程（《经济学与百度商业应用》《漫画机器学习》等），其中的大数据分析课程《数据分析的道与术》获在线评分的最受欢迎产品技术系列课程。</td>
    <td><b>互联网促销策略中的统计模型</b><br><br>在搜索推广的优惠促销领域，如何设计与众不同的营销思路（价格歧视、博弈机制下的竞争传播），及在其中的机器学习模型。主要点明如何讲经济学模型的一些理论，怎样和统计模型做很好的结合，跨领域的发挥巨大价值，这个项目获得了首届100万美金的百度最高奖。</td>
</tr>





  </tbody>
</table>
